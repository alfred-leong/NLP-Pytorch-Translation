# Seq2Seq Translation with Attention - PyTorch Tutorial

This project follows the [Seq2Seq Translation Tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) from the official PyTorch documentation. The tutorial demonstrates building a sequence-to-sequence (Seq2Seq) model with attention for translating between languages.

## Overview

The tutorial covers:
- Building encoder and decoder RNNs with GRU.
- Implementing Bahdanau-style attention for better translation.
- Training with teacher forcing and evaluating results.
