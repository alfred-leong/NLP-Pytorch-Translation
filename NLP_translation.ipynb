{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XxdmHAW7nhXz"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(\" \"):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "QHkOFbgSn9cS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ],
      "metadata": {
        "id": "XOw6tKts2GG5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "  print(\"Reading lines...\")\n",
        "\n",
        "  lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split(\"\\n\")\n",
        "  pairs = [[normalizeString(s) for s in l.split(\"\\t\")] for l in lines]\n",
        "\n",
        "  if reverse:\n",
        "    pairs = [list(reversed(p)) for p in pairs]\n",
        "    input_lang = Lang(lang2)\n",
        "    output_lang = Lang(lang1)\n",
        "  else:\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "  return input_lang, output_lang, pairs\n"
      ],
      "metadata": {
        "id": "ggIWfVtT4rgX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "UtlrRKFK5ZhH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=True):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "  print(\"Read %s sentence pairs\" % len(pairs))\n",
        "  pairs = filterPairs(pairs)\n",
        "  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  print(\"Counted words:\")\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name, output_lang.n_words)\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmw0xPkA6OiT",
        "outputId": "88c950f3-f86b-42c7-dc68-7caa3fe4a4db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "['je suis pret a vous suivre', 'i am ready to follow you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    output, hidden = self.gru(embedded)\n",
        "    return output, hidden"
      ],
      "metadata": {
        "id": "NaG6SujT7KIj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "    batch_size = encoder_outputs.size(0)\n",
        "    decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "      decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "      decoder_outputs.append(decoder_output)\n",
        "      if target_tensor is not None:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "      else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        _, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze(-1).detach()   # detach from history as input\n",
        "\n",
        "    decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "    decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "    return decoder_outputs, decoder_hidden, None\n",
        "\n",
        "  def forward_step(self, input, hidden):\n",
        "    output = self.embedding(input)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.out(output)\n",
        "    return output, hidden\n"
      ],
      "metadata": {
        "id": "GKthk0Zv9ePL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "    self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "    self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, query, keys):\n",
        "    scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "    scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "    context = torch.bmm(weights, keys)\n",
        "\n",
        "    return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "    super(AttnDecoderRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.attention = BahdanauAttention(hidden_size)\n",
        "    self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "    batch_size = encoder_outputs.size(0)\n",
        "    decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_outputs = []\n",
        "    attentions = []\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "      decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "          decoder_input, decoder_hidden, encoder_outputs\n",
        "      )\n",
        "      decoder_outputs.append(decoder_output)\n",
        "      attentions.append(attn_weights)\n",
        "\n",
        "      if target_tensor is not None:\n",
        "        decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "      else:\n",
        "        _, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "    decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "    decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "    attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "    return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "  def forward_step(self, input, hidden, encoder_outputs):\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    query = hidden.permute(1, 0, 2)\n",
        "    context, attn_weights = self.attention(query, encoder_outputs)\n",
        "    input_gru = torch.cat((embedded, context), dim=2)\n",
        "    output, hidden = self.gru(input_gru, hidden)\n",
        "    output = self.out(output)\n",
        "    return output, hidden, attn_weights\n"
      ],
      "metadata": {
        "id": "3yaULfHl_bhm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  output_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, output_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "  input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "  n = len(pairs)\n",
        "  input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "  target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "  for idx, (inp, tgt) in enumerate(pairs):\n",
        "    inp_ids = indexesFromSentence(input_lang, inp)\n",
        "    tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "    inp_ids.append(EOS_token)\n",
        "    tgt_ids.append(EOS_token)\n",
        "    input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "    target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "  train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                             torch.LongTensor(target_ids).to(device))\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  return input_lang, output_lang, train_dataloader\n"
      ],
      "metadata": {
        "id": "yjwpAOrTBlRz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "  total_loss = 0\n",
        "  for data in dataloader:\n",
        "    input_tensor, target_tensor = data\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "    decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "    loss = criterion(\n",
        "      decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "      target_tensor.view(-1)\n",
        "    )\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "dNB50pETEDh9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "  m = math.floor(s / 60)\n",
        "  s = s - m * 60\n",
        "  return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s / (percent)\n",
        "  rs = es - s\n",
        "  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "QgRdkOr-EnTd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  loc = ticker.MultipleLocator(base=0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)"
      ],
      "metadata": {
        "id": "wfqatqC2FuKH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0\n",
        "  plot_loss_total = 0\n",
        "\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "\n",
        "  showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "Ya518eguE-pn"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "    decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "    _, topi = decoder_outputs.topk(1)\n",
        "    decoded_ids = topi.squeeze()\n",
        "\n",
        "    decoded_words = []\n",
        "    for idx in decoded_ids:\n",
        "      if idx.item() == EOS_token:\n",
        "        decoded_words.append('<EOS>')\n",
        "        break\n",
        "      decoded_words.append(output_lang.index2word[idx.item()])\n",
        "  return decoded_words, decoder_attn\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "  for i in range(n):\n",
        "    pair = random.choice(pairs)\n",
        "    print('>', pair[0])\n",
        "    print('=', pair[1])\n",
        "    output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    print('<', output_sentence)\n",
        "    print('')"
      ],
      "metadata": {
        "id": "kG8uZpFgFrPo"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6MQZVpcHBi0",
        "outputId": "3b3341ca-edee-4336-e9b7-74d42862a61e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "0m 39s (- 9m 58s) (5 6%) 1.5179\n",
            "1m 19s (- 9m 16s) (10 12%) 0.6789\n",
            "1m 59s (- 8m 37s) (15 18%) 0.3562\n",
            "2m 39s (- 7m 59s) (20 25%) 0.1999\n",
            "3m 20s (- 7m 20s) (25 31%) 0.1261\n",
            "4m 5s (- 6m 49s) (30 37%) 0.0883\n",
            "4m 45s (- 6m 7s) (35 43%) 0.0681\n",
            "5m 25s (- 5m 25s) (40 50%) 0.0552\n",
            "6m 5s (- 4m 44s) (45 56%) 0.0474\n",
            "6m 46s (- 4m 4s) (50 62%) 0.0422\n",
            "7m 26s (- 3m 22s) (55 68%) 0.0385\n",
            "8m 6s (- 2m 42s) (60 75%) 0.0361\n",
            "8m 46s (- 2m 1s) (65 81%) 0.0339\n",
            "9m 26s (- 1m 20s) (70 87%) 0.0325\n",
            "10m 6s (- 0m 40s) (75 93%) 0.0310\n",
            "10m 45s (- 0m 0s) (80 100%) 0.0298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dssy4d8mNPVF",
        "outputId": "a6ecaab4-2d2d-4330-d14a-a642b4225f21"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> vous etes plein de surprises\n",
            "= you re full of surprises\n",
            "< you re full of surprises <EOS>\n",
            "\n",
            "> vous dites toujours cela\n",
            "= you re always saying that\n",
            "< you re always saying that <EOS>\n",
            "\n",
            "> il est fier que son pere soit riche\n",
            "= he is proud of his father being rich\n",
            "< he is proud of his father being rich <EOS>\n",
            "\n",
            "> il se tient sur la colline\n",
            "= he is standing on the hill\n",
            "< he is standing on the hill the examination <EOS>\n",
            "\n",
            "> je suis si malade\n",
            "= i am so sick\n",
            "< i am so sick <EOS>\n",
            "\n",
            "> elle nous apprend le francais\n",
            "= she s teaching us french\n",
            "< she s teaching us french <EOS>\n",
            "\n",
            "> j obtiens un diplome superieur en education\n",
            "= i m getting a master s degree in education\n",
            "< i m getting a master s degree in education <EOS>\n",
            "\n",
            "> elle est coupable de vol\n",
            "= she is guilty of theft\n",
            "< she is guilty of theft theft <EOS>\n",
            "\n",
            "> vous ne m aidez pas\n",
            "= you re not helping me\n",
            "< you re not helping me <EOS>\n",
            "\n",
            "> je ne suis pas assez bonne pour vous\n",
            "= i m not good enough for you\n",
            "< i m not good enough for you <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "  output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "  print('input = ', input_sentence)\n",
        "  print('output = ', ' '.join(output_words))\n",
        "  showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "\n",
        "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
        "\n",
        "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
        "\n",
        "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
        "\n",
        "evaluateAndShowAttention('je suis reellement fiere de vous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vom9qs5-W2Sp",
        "outputId": "f83820ca-15b4-411e-e848-f3cf738ee17b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input =  il n est pas aussi grand que son pere\n",
            "output =  he is not as tall as his father <EOS>\n",
            "input =  je suis trop fatigue pour conduire\n",
            "output =  i m too tired to drive <EOS>\n",
            "input =  je suis desole si c est une question idiote\n",
            "output =  i m sorry if this is a stupid question <EOS>\n",
            "input =  je suis reellement fiere de vous\n",
            "output =  i m really proud of you <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-79a5c044067a>:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-70-79a5c044067a>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38GWLSNJXaXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}